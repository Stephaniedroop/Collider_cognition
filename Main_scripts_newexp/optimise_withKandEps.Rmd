---
title: "optimise"
output: html_document
date: "2025-02-27"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

# Summary

Takes data created in `modelCombLesions.Rmd`


# STEP 1: READ IN 

There are four cognitive modules: Actual causality, Inference, causal Selection and Kindness.
The first three are lesioned in the imported data itself, and Kindness in contrast is lesioned by the presence or absence of the 'behaviourally meaningful' parameter Kappa on that data. 

So the code below roughly imports data of 8 models, then runs a set of likelihood and optimisation functions for a series of 8 models with K, epsilon and tau, THEN runs a slightly modified set of likelihood and optimisation functions to optimise the equivalent series of that 8 without Kindness with only epsilon and tau. 

First some prelim setup and renaming:

```{r, include=FALSE}

df <- read.csv('../model_data/modelAndDataUnfitpn.csv') # 288 obs of 21

# Let's create variables coding the actual observation
df.map<-data.frame(condition=c('c1','c2','c3','c4','c5','d1','d2','d3','d4','d5','d6','d7'),
                   A=c(0,0,1,1,1, 0,0,0,1,1,1,1),
                   B=c(0,1,0,1,1, 0,1,1,0,0,1,1),
                   E=c(0,0,0,0,1, 0,0,1,0,1,0,1))

for (i in 1:nrow(df))
{
  df$A[i]<-df.map$A[df.map$condition==df$trialtype[i]]
  df$B[i]<-df.map$B[df.map$condition==df$trialtype[i]]
  df$E[i]<-df.map$E[df.map$condition==df$trialtype[i]]
}


df <- df %>%
  mutate(include = !( (node3=='B=0' & B==1) | (node3=='B=1' & B==0) | (node3=='A=0' & A==1) | (node3=='A=1' & A==0)))

df <- df %>% rename(trial_id = pg_tt)
# Any result not 'real' or 'Actual' still needs some small prob value allocated by the softmax, so give -Inf here
df[df$include == FALSE, 9:16] <- -Inf

```

How many even were the nonsensical ones?
```{r}
nons <- sum(df$n[df$include == FALSE]) #132 / 2580

ppl <- df %>% group_by(trial_id) %>% summarise(n=sum(n)) 
sum(ppl$n) # 2580

# For old experiment it is 50/3408 = .0147
# For new experiment it is 132/2580 = .0511

```

Names of models:

With Kindness:

full
noAct
noInf
noSelect
noActnoInf
noActnoSelect
noActnoInfnoSelect
noInfnoSelect

Without Kindness: in other words the same list but without Kind/kappa:

noKind
noActnoKind
noActnoInfnoKind
noActnoKindnoSelect
noInfnoKindnoSelect
noInfnoKind
noKindnoSelect
noActnoInfnoKindnoSelect

The two different sets have different numbers of parameters. 
So everything we do, we need to do twice.

Here is a series of functions to generate model predictions and optimise the NLL.

# First, with Kindness/kappa

Internet says:
- For the pars you want bounded 0,1: use exp(pars)/(1 + exp(pars)) to optimise in logit space. Retrieve with logistic function plogis(optimised par).
- For the pars you want more than 0 but upper unbounded, use exp(par) to optimise in log space. Retrieve with exp(optimised par). 


```{r, include=FALSE}
# Initial values for testing:
pars <- c(1, 1, 1)
mod_name <- 'full'
i <- 1

# Function to get the model likelihood.
model_likelihood <- function(pars, df, mod_name)
{
  # 
  epsilon <- plogis(pars[1])  # exp(pars[1])/(1+exp(pars[1])) # 
  tau <- exp(pars[2]) # exp(pars[2])/(1+exp(pars[2])) #   
  kappa <- exp(pars[3])
  tt <- unique(df$trial_id) 
  
  nlls <- rep(NA, length(tt))
  for (i in 1:length(tt))
  {
    n <- df$n[df$trial_id==tt[i]] 
    mod_raw <- df[[mod_name]][df$trial_id==tt[i]] 
    
    # A distance measure which gets parametrised by kappa
    dist <- df$tv[df$trial_id==tt[i]] 
    dist[is.na(dist)] <- 0
    
    # Model predictions
    mpred <- epsilon * (1/8) + (1-epsilon) * (exp( (mod_raw + kappa*dist)/tau) / sum(exp( (mod_raw + kappa*dist)/tau)))
    
    nlls[i] <-  -sum(log(mpred)*n) # Get likelihood for this trial
  }
  
  sum(nlls) # Return the total likelihood
}

```

A function to generate actual predictions for each node in each conditions:

```{r, include=FALSE}
generate_predictions <- function(mod_name, df, pars) {
  epsilon <- plogis(pars[1]) # exp(pars[1])/(1+exp(pars[1])) #  
  tau <- exp(pars[2]) #exp(pars[2])/(1+exp(pars[2])) # 
  kappa <- exp(pars[3])
  tt <- unique(df$trial_id)
  
  do.call(rbind, lapply(tt, function(t_id) {
    trial_rows <- df$trial_id == t_id 
    mod_raw <- df[[mod_name]][trial_rows]
    
    # A distance measure which will get parametrised by kappa
    dist <- df$tv[trial_rows]
    dist[is.na(dist)] <- 0
    
    # Model predictions
    mpred <- epsilon * (1/8) + (1-epsilon) * (exp( (mod_raw + kappa*dist)/tau) / sum(exp( (mod_raw + kappa*dist)/tau)))
    
    data.frame(
      model = mod_name,
      trial_id = t_id,
      node3 = df$node3[trial_rows],
      predicted_prob = mpred
    )
  }))
}


```


Optimise the parameters:

```{r, include=FALSE}

optimize_models <- function(model_names, df, initial_values = c(1, 1, 1)) { 
  optimize_single <- function(mod_name) {
    result <- tryCatch({
      optim(par = initial_values, 
          fn = model_likelihood, 
          df = df, 
          mod_name = mod_name)
  }, error = function(e) {
      message("Error in optimization for model ", mod_name, ": ", e$message)
      return(list(par = c(NA, NA, NA), value = NA))
    })
    return(result)
  }
  
  out <- lapply(model_names, optimize_single)
  names(out) <- model_names
  
  mfs <- data.frame(
    model = names(out),
    epsilon = plogis(sapply(out, function(x) x$par[1])), 
    tau = exp(sapply(out, function(x) x$par[2])), # 
    kappa = exp(sapply(out, function(x) x$par[3])),
    logl = -sapply(out, function(x) x$value)
  ) %>%
    mutate(BIC = -2 * logl + 3 * log(sum(df$n)))
  
  # To actually generate predictions 
  predictions <- do.call(rbind, lapply(names(out), function(mod_name) {
    if(!any(is.na(out[[mod_name]]$par))) {
      generate_predictions(
        mod_name = mod_name,
        df = df,
        pars = out[[mod_name]]$par
      )
    }
  }))
  
  list(
    model_fits = mfs %>% mutate(epsilon = format(epsilon, digits=3), tau = format(tau, digits=3), kappa = format(kappa, digits=3)),
    predictions = predictions
  )
}

# Usage:
model_names <- c('full', 
                 'noAct', 
                 'noInf', 
                 'noSelect', 
                 'noActnoInf', 
                 'noActnoSelect', 
                 'noInfnoSelect', 
                 'noActnoInfnoSelect')  

results1 <- optimize_models(model_names, df)

print(results1)
```

# Now time for the two-parameter, No-Kind version


```{r, include=FALSE}
# Initial values for testing:
pars <- c(1, 1)
mod_name <- 'noKind'
i <- 1

# Function to get the model likelihood.
model_likelihood2 <- function(pars, df, mod_name)
{
  # 
  epsilon <- plogis(pars[1]) # exp(pars[1])/(1+exp(pars[1])) #  
  tau <-  exp(pars[2]) # exp(pars[2])/(1+exp(pars[2])) # 
  #kappa <- exp(pars[3])
  tt <- unique(df$trial_id) 
  
  nlls <- rep(NA, length(tt))
  for (i in 1:length(tt))
  {
    n <- df$n[df$trial_id==tt[i]] 
    mod_raw <- df[[mod_name]][df$trial_id==tt[i]] 
    #mod_raw[is.na(mod_raw)] <- 0 
    
    #dist <- df$tv[df$trial_id==tt[i]] 
    #dist[is.na(dist)] <- 0
    
    mpred <- epsilon * (1/8) + (1-epsilon) * (exp(mod_raw/tau) / sum(exp(mod_raw/tau)))
    
    nlls[i] <-  -sum(log(mpred)*n) # Get likelihood for this trial
  }
  
  sum(nlls) # Return the total likelihood
}

```

A function to enerate actual predictions for each node in each conditions:

```{r, include=FALSE}
generate_predictions2 <- function(mod_name, df, pars) {
  epsilon <- plogis(pars[1])  #exp(pars[1])/(1+exp(pars[1])) # 
  tau <- exp(pars[2]) #exp(pars[2])/(1+exp(pars[2])) # 
  #kappa <- exp(pars[3])
  tt <- unique(df$trial_id)
  
  do.call(rbind, lapply(tt, function(t_id) {
    trial_rows <- df$trial_id == t_id 
    mod_raw <- df[[mod_name]][trial_rows]
    #mod_raw[is.na(mod_raw)] <- 0
    #dist <- df$tv[trial_rows]
    #dist[is.na(dist)] <- 0
    
    mpred <- epsilon * (1/8) + (1-epsilon) * (exp(mod_raw/tau) / sum(exp( mod_raw/tau)))
    
    data.frame(
      model = mod_name,
      trial_id = t_id,
      node3 = df$node3[trial_rows],
      predicted_prob = mpred
    )
  }))
}


```


Optimise the parameters:

```{r, include=FALSE}

optimize_models2 <- function(model_names, df, initial_values = c(1, 1)) { 
  optimize_single <- function(mod_name) {
    result <- tryCatch({
      optim(par = initial_values, 
          fn = model_likelihood2, 
          df = df, 
          mod_name = mod_name)
  }, error = function(e) {
      message("Error in optimization for model ", mod_name, ": ", e$message)
      return(list(par = c(NA, NA), value = NA))
    })
    return(result)
  }
  
  out <- lapply(model_names, optimize_single)
  names(out) <- model_names
  
  mfs <- data.frame(
    model = names(out),
    epsilon = plogis(sapply(out, function(x) x$par[1])), #plogis(logodd) gives prob
    tau = exp(sapply(out, function(x) x$par[2])),
    #kappa = exp(sapply(out, function(x) x$par[3])),
    logl = -sapply(out, function(x) x$value)
  ) %>%
    mutate(BIC = -2 * logl + 2 * log(sum(df$n)))
  
  # To actually generate predictions 
  predictions <- do.call(rbind, lapply(names(out), function(mod_name) {
    if(!any(is.na(out[[mod_name]]$par))) {
      generate_predictions2(
        mod_name = mod_name,
        df = df,
        pars = out[[mod_name]]$par
        # epsilon = plogis(sapply(out, function(x) x$par[1])),
    # tau = plogis(sapply(out, function(x) x$par[2])),
    # kappa = exp(sapply(out, function(x) x$par[3])),
      )
    }
  }))
  
  list(
    model_fits = mfs %>% mutate(epsilon = format(epsilon, digits=3), tau = format(tau, digits=3)),
    predictions = predictions
  )
}

# Usage:
model_names2 <- c('noKind', 
                 'noActnoKind', 
                 'noInfnoKind', 
                 'noKindnoSelect', 
                 'noActnoInfnoKind', 
                 'noActnoKindnoSelect', 
                 'noInfnoKindnoSelect', 
                 'noActnoInfnoKindnoSelect',
                 'baseline')  

# Replace the predictions with the model_names2 (this is fine because the presence or absence of the other modules remains same)
df <- df %>% relocate(baseline, .before = Actual)
colnames(df)[9:17] <- model_names2

results2 <- optimize_models2(model_names2, df)

print(results2)
```


Put all the model preds together to then plot against people, so only do this bit once we are happy with both sets of models:

```{r}
allpredictions <- rbind(results1$predictions, results2$predictions) # 4608: 36tt x 8 nodevals x 16 models 
```


```{r}
df_wide <- allpredictions %>%
  pivot_wider(
    id_cols = c(trial_id, node3),
    names_from = model,
    values_from = predicted_prob
  )

```

Merge back in the participant numbers and then send for plotting.

```{r}
justppt <- df %>% select(trial_id, node3, n, prop, pgroup, Actual, A, B, E, include)

fitforplot <- merge(df_wide, justppt, by = c('trial_id', 'node3'))
fitforplot[, 22][is.na(fitforplot[, 22])] <- FALSE
```

```{r}
write.csv(fitforplot, '../model_data/fitforplot16mpn.csv')  
```